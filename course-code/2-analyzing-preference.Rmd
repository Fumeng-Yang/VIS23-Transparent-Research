---
title: "Analyzing the preference data"
output: 
  html_document: 
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: no
    df_print: kable
    number_sections: yes
    theme: flatly
    highlight: tango
date: "`r format(Sys.time(), '%B %d, %Y')`"
author: "Fumeng Yang, Abhraneel Sarma, Maryam Hedayati"
---


```{r setup, message=FALSE}
library(tidyverse, quietly = TRUE) # data manipulation
library(ggdist, quietly = TRUE) # uncertainty vis
library(brms, quietly = TRUE) # bayesian modeling
library(tidybayes, quietly = TRUE) # deal with posteriors
library(posterior, quietly = TRUE) # deal with posteriors
library(modelr, quietly = TRUE)
library(broom, quietly = TRUE)
library(distributional, quietly = TRUE)
```

```{r message=FALSE}
theme_set(theme_ggdist())

scale_color_vis23 = \(...) scale_color_manual(..., 
                                              values = c("cat" = '#e888b3', 
                                                         "logo" ='#277cbd'),
                                              aesthetics = c("color", "fill")
)
```


# Introduction

The goal of most data analysis for scientific studies is not descriptive, but rather inferential i.e. to make generalisable inferences regarding the phenomena of interest. In this example, the (trivial) question is which badge is liekly to be preferred by the audience.

There are several different ways of analysing this dataset:

- we calculate mean and 95% CI of the data aggregated for each respondant for each badge (which can be assumed to be normally distributed)
- we can conduct a t-test or a regression (which is essentially similar to the previous step, but provides statistics such as p-values)
- we can use an ordinal regression model to analyse the data

In this document, we will implement each of the analyses, and discuss ways to visualise the results:

```{r}
df = read_csv(file = 'data/preference.csv', show_col_types = FALSE)

df_aggregated = df |> 
  # we aggregate per participant x design
  group_by(participantID, design) |> 
  reframe(mean_response = mean(response), sd_response = sd(response))
```


# Fully-aggregated data

Let us say, we want to determine, on average, which badge is rated higher. One way to do this would be to calculate the mean and standard error of the responses aggregated at the participant level:

```{r}
n = length(unique(df_aggregated$participantID))

df_mean = df_aggregated |> 
  group_by(design) |> 
  reframe(preference_mean = mean(mean_response), preference_se = sd(mean_response) / sqrt(n - 1))
```

The code below visualises the 95% Confidence Interval for the preferences for the two badges. The errorbars are drawn using `geom_errorbarh()` function which takes in the arguments `x`, `xmin`, `xmax` and `y`; the `xmin` and `xmax` represent the ends of the error bars which are calculated as $qnorm(0.025) \times se$ and $qnorm(0.975) \times se$, where the $se$ is calculated as the standard deviation divided by $\sqrt{n - 1}$.

```{r, fig.height = 2, fig.width = 7}
df_mean |> 
  ggplot(aes(x = preference_mean,  y = design, fill = design, color = design)) + 
  geom_errorbarh(aes(xmin = preference_mean + qnorm(0.025) * preference_se, xmax = preference_mean + qnorm(0.975) * preference_se), height = 0, linewidth = 1) + 
  geom_point(size = 3) + 
  scale_x_continuous(breaks = 1:7, limits = c(0.9, 5.1)) + 
  labs(x = "preference") +
  scale_color_vis23()
```

This graph shows that the survey participants likely rated the cat badge higher on average than the logo badge, but there was a lot of variation in participants individual responses, which are not expressed using just confidence intervals. Moreover, this visualisation is less usable for (probability of superiority questions such as "what is the probability that someone is likely to prefer the cat badge over the logo badge?").

Work by [Zhang et al.](https://www.pnas.org/doi/abs/10.1073/pnas.2302491120) shows that visualising the actual responses, in addition to the mean and 95% CIs can help participants to interpret the variability in the responses.

```{r, fig.height = 2, fig.width = 7}
df_mean |> 
  ggplot(aes(x = preference_mean,  y = design, fill = design, color = design)) + 
  geom_errorbarh(aes(xmin = preference_mean + qnorm(0.025) * preference_se, xmax = preference_mean + qnorm(0.975) * preference_se), height = 0, linewidth = 1) + 
  geom_point(size = 3) + 
  geom_point(data = df, aes(x = response, y = design), position = position_jitter(width = .05, height = .2, seed = 1234), alpha = 0.5) +
  scale_x_continuous(breaks = 1:7, limits = c(0.9, 5.1)) +
  labs(x = "preference") +
  scale_color_vis23()
```

Now, we see that many more participants clearly prefer the cat badge than the logo badge. In other words, this representation allows you to answer two questions:
1. which badge is rated higher on average?
2. what proportion of participants are likely to rate the cat badge higher than the logo badge?

# Regression

The second approach was using a linear regression model. In cases such as this, where the independent variable is discrete, it is essentially similar to the previous approach. However, this method is much more extensible.

Let us first fit the model, and look at the coefficients:

```{r}
m.linear = lm(mean_response ~ 0 + design, data = df_aggregated)

summary(m.linear)
```

We can plot the results of this model using:

- confidence intervals
- density plots
- gradient interval plots

(or other ways, but those do not seem very relevant for reporting scientific results in a paper)

### Confidence Intervals

As you can see, these plots are very much exactly similar to the plots created previously.

```{r, fig.height = 3, fig.width = 7}
m.linear |> 
  tidy() |> 
  mutate(term = ifelse(term == "designcat", "cat", "logo")) |> 
  ggplot(aes(y = term, color = term)) +
  stat_pointinterval(
    aes(xdist = dist_student_t(df = df.residual(m.linear), mu = estimate, sigma = std.error)),
    alpha = 0.7,
    .width = .95
  ) +
  scale_color_vis23() +
  scale_x_continuous(breaks = 1:7, limits = c(0.9, 5.1)) +
  theme(legend.position = "none")
```

### Density plots

Density plots show the entire distribution of the estimated model coefficients. You can choose to either add or omit the confidence intervals to these density plots.

```{r, fig.height = 3, fig.width = 7}
m.linear |> 
  tidy() |> 
  mutate(term = ifelse(term == "designcat", "cat", "logo")) |> 
  ggplot(aes(y = term, fill = term)) +
  stat_slab(
    aes(xdist = dist_student_t(df = df.residual(m.linear), mu = estimate, sigma = std.error)),
    alpha = 0.7,
    .width = .95
  ) +
  scale_color_vis23() +
  scale_x_continuous(breaks = 1:7, limits = c(0.9, 5.1)) +
  theme(legend.position = "none")
```

### Gradient plots

A third approach would be to use gradient intervals which encodes uncertainty to opacity. Like density plots, you can augment them using point intervals or error bars.

```{r, fig.height = 3, fig.width = 7}
m.linear |> 
  tidy() |> 
  mutate(term = ifelse(term == "designcat", "cat", "logo")) |> 
  ggplot(aes(y = term, fill = term)) +
  stat_gradientinterval(
    aes(xdist = dist_student_t(df = df.residual(m.linear), mu = estimate, sigma = std.error)),
    geom = "slab",
    fill_type = "gradient",
    height = .5
  ) +
  scale_color_vis23() +
  scale_x_continuous(breaks = 1:7, limits = c(0.9, 5.1)) +
  theme(legend.position = "none")
```

# Bayesian regression

The same linear regression model can be implemented using Bayesian regression methods. In R, we recommend using `brms` which provides syntax which is very similar to the `glmer` syntax. Bayesian models require you to specify prior distributions, and define a likelihood function. The regression model estimates a posterior distribution, using Bayes rule.

```{r}
m.linear.bayes = brm(
  preference_mean ~ design,
  data = df_aggregated,
  family = 'gaussian',
  backend = 'cmdstanr',
  refresh = 2000,
  cores = 4,
  chains = 4,
  file = "data/likert-reg_model",
  prior = c(prior(normal(0,2.5), class='b'),
            prior(normal(0,2.5), class='Intercept'),
            prior(normal(0,1), class='sigma', lb = 0))
)
```

Once you have the fitted model, you will need to extract posterior draws. The `tidybayes` R package facilitates this. For instance, the code below shows five posterior draws for each design.

```{r}
tibble(design = c('logo', 'cat')) |> 
  add_epred_draws(m.linear.bayes, value = '.value', ndraws = 5)
```

We store these posterior draws into the `posterior` variable:

```{r}
posteriors = 
  tibble(design = c('logo', 'cat')) |> 
  add_epred_rvars(m.linear.bayes, value = '.value')
```

We can then visualise these posterior draws:

```{r fig.width = 7, fig.height = 3}
 posteriors |> 
  ggplot() +
  stat_slab(aes(xdist = .value, y = design, fill = design)) +
  coord_cartesian(xlim = c(0.8, 5.2)) +
  scale_color_vis23() +
  theme(legend.position = "none")
```

We can also compute the difference between the two conditions, two estimate the probability of one badge being preferred over the other, and by how much.

```{r fig.width = 7, fig.height = 2}
 posteriors |> 
  compare_levels(variable = '.value', by = design, comparison = list(c('cat', 'logo'))) |> 
  ggplot() +
  stat_slab(aes(xdist = .value, y = design), alpha = .7) +
  geom_vline(xintercept = 0, linetype = 2) + 
  scale_color_vis23() +
  xlab('') + ylab('')
```

## Ordinal regression

An alternative way of analysing the likert data is using an ordinal regression model. In modeling each outcome value, we have to keep in mind that these values are ordered, because 5 is greater than 4, which is greater than 3, and so on. But unlike a count, the differences in value are not necessarily equal. It might be much harder to move someoneâ€™s preference for the cat badge from 1 to 2 than it is to move it from 3 to 4, for example. Just treating ordered categories as continuous measures is not a good idea [McElreath, Statisitical Rethinking](). Thus, ordinal regression is perhaps more appropriate for modeling likert data.

```{r}
priors.ord = c(
  prior(normal(0, 1.5), class = "b"),
  prior(student_t(3, 0, 2.5), class = "Intercept"),
  prior(student_t(3, 0, 1), class = "sd")
)

m.ord = brm(
  response ~ design + (1 | participantID) + (1|qid),
  family = cumulative(link = "logit"), 
  prior = priors.ord,
  data = df, 
  file = "data/likert-ordinal_model",
  backend = "cmdstanr",
  cores = 4, chains = 4, iter = 4000, warmup = 3000, control = list(adapt_delta = 0.9))
```

Ordinal regression estimates the probability that a participant will choose each likert item (for each condition). Below, we visualise these (cumulative) probabilities along with the associated uncertainty. Note that both the probabilities some up to 1.

```{r, fig.height = 3, fig.width = 7}
df |> 
  data_grid(design) |> 
  add_epred_draws(m.ord, re_formula = NA, ndraws = 100, seed = 1234) |> 
  group_by(design, .draw) |> 
  mutate(.epred = cumsum(.epred)) |> 
  ggplot() +
  stat_pointinterval(aes(x = .category, y = .epred, colour = design), .width = .95, position = position_dodge(width = .1)) +
  # geom_line(aes(x = .category, y = .epred, group = design, colour = design), position = position_dodge(width = .05)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2)) +
  scale_color_vis23() +
  theme(legend.position = "none")
```

This visualisation shows you that the logo badge is much more likelier to receive lower ratings (1 - 4) than the cat badge. However, this representation is has some shortcomings.

Alternatively, ...

```{r fig.width = 7, fig.height = 3}
df |> 
  data_grid(design, qid) |> 
  add_epred_draws(m.ord, re_formula = ~ (1 | qid), ndraws = 1000, seed = 1234) |> 
  mutate(.epred = .epred * as.numeric(.category)) |> 
  group_by(design, .draw, qid) |> 
  summarise(.epred = sum(.epred), .groups = "drop_last") |>
  summarise(.epred = mean(.epred), .groups = "drop_last") |>
  ggplot() +
  stat_slab(aes(x = .epred, y = design, fill = design), scale = 0.8, alpha = 0.4) +
  stat_pointinterval(aes(x = .epred, y = design, colour = design), .width = .95) +
  coord_cartesian(xlim = c(0.8, 5.2)) +
  scale_color_vis23() +
  theme(legend.position = "none")
```


```{r fig.width = 7, fig.height = 3}
df |> 
  data_grid(design, qid) |> 
  add_epred_draws(m.ord, re_formula = ~ (1 | qid), ndraws = 2000, seed = 1234) |> 
  mutate(.epred = .epred * as.numeric(.category)) |> 
  group_by(design, .draw, qid) |> 
  summarise(.epred = sum(.epred), .groups = "drop_last") |>
  summarise(.epred = mean(.epred), .groups = "drop_last") |>
  ggplot() +
  stat_slab(aes(x = .epred, y = design, fill = design), scale = 0.7, alpha = 0.4, .width = .95) +
  geom_point(data = df, aes(x = response, y = design, colour = design), position = position_jitter(width = .05, height = .1, seed = 1234), alpha = 0.7) +
  coord_cartesian(xlim = c(0.8, 5.2)) +
  scale_color_vis23() +
  theme(legend.position = "none")
```







